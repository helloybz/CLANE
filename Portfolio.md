# Content- and Link-Aware Network Embedding

## 1. Network Embedding

   이 세상에는 다양한 네트워크 데이터가 존재합니다.
   사회관계망서비스의 사용자 간 친구 관계, 문헌 간 인용 관계, 우리가 매일 이용하는 월드 와이드 웹 등이 그 예시입니다.
   네트워크 데이터의 규모가 거대해지면서, 그 안에 내재되어 있는 정보들을 활용하려는 시도가 많아지고 있습니다.
   데이터로부터 패턴을 찾아내기 위해 머신러닝

   네트워크 데이터의 자료구조인 그래프는 정점들(vertices)의 집합과 정점들 사이를 연결하는 간선들(edges)의 집합으로 구성되어 있으며, **관계**라는 복잡한 정보를 나타내기에 유용합니다.
   머신러닝 알고리즘은 일반적으로 수치 데이터를 그 입력으로 하는 반면, 네트워크 데이터의 정점들 사이의 **관계**는 수치 형태가 아닙니다.
   이를 위해, 정점들 사이의 **관계**를 수치화하는 것이 **네트워크 임베딩**기법입니다.

   [**임베딩(Embedding)**](https://en.wikipedia.org/wiki/Embedding)이란 수치 형태를 갖지 않는 데이터들을 임의의 벡터 공간에 할당하는 과정, 또는 할당된 값 자체를 의미합니다.
   벡터 공간에 할당한다는 것은 데이터를 일련의 숫자들로 표현한다는 뜻입니다.
   마찬가지로, 네트워크 임베딩이란 네트워크 데이터를 임의의 벡터 공간에 할당하여 일련의 숫자들로 표현하는 과정입니다.
   그래프를 통째로 임베딩할 수도 있고 간선들을 임베딩할 수도 있습니다만, 정점들 각각을 임베딩하는 것이 일반적입니다.

   그래프의 정점들이 갖는 데이터는 이웃하는 다른 정점들이므로, 수치 형태를 갖지 않기 때문에 임베딩을 적용하는 것이 좋습니다.
   다만, 서로 긴밀이 연결되어 있어 관계가 깊은 정점들은 좌표 공간에 가까이 위치하도록, 그렇지 않은 정점들을 비교적 멀리 위치하도록 할당하는 것이 중요합니다.

   ![네트워크 데이터(좌)와 네트워크 임베딩(우)의 예시](./resources/Deepwalk_Karate.png)*그림 1. 네트워크 데이터(좌)와 네트워크 임베딩(우)의 예시*

   [그림 1]은 대표적인 네트워크 임베딩 기법 중 하나인 [Deepwalk](https://arxiv.org/abs/1403.6652)의 적용 예시입니다.
   왼쪽 그림은 [Zachary's karate club](https://en.wikipedia.org/wiki/Zachary%27s_karate_club)이라는 작은 네트워크 데이터를 시각화한 것이고, 오른쪽 그림은 이 네트워크 안의 정점들을 2차원의 공간에 할당한 결과입니다.

   각 정점의 색깔은 Ground Truth로, 정점이 속한 소그룹을 나타냅니다.
   Ground Truth는 임베딩 과정에는 사용되지 않고 임베딩이 얼마나 잘 되었는지 검증하는 용도로 활용됩니다.
   임베딩 결과를 보면 같은 색깔의 정점끼리 좌표공간에 모여 있어 네트워크의 구조적 정보가 잘 반영되었음을 알 수 있습니다.
   네트워크의 정보를 잘 반영한 임베딩은 다양한 머신러닝 모델의 입력으로 활용해 더 유용한 정보를 얻을 수 있게 됩니다.

## 2. Random Walks

   그렇다면 그래프를 구성하는 정점들 간의 **관계**를 잡아내는 방법에는 어떤 것이 있을까요?
   대표적으로 [무작위 행보(random walk)](https://en.wikipedia.org/wiki/Random_walk)가 있습니다.
   무작위 행보는 본디 이 글에서 소개되는 것보다 더 일반적인 개념으로, 수학뿐만 아니라 자연과학, 컴퓨터공학, 경제학 등 분야를 막론하고 무작위로 상태가 변하여 가는 것들을 모델링할 때 쓰입니다.

   무작위 행보는 **확률 과정**의 일종으로 일련의 **확률 변수**들로 구성되는데, 이 확률 변수들은 시간적 순서를 가지면서 시간이 지남에 따른 상태의 변화를 나타냅니다.
   무작위 행보는 **확률 과정**의 일종으로 시간적 순서를 갖는 **확률 변수**들로 구성되어 있습니다.
   이 확률 변수들은 각 시점의 상태를 나타내는데, 다음 시점의 상태는 현재 시점의 상태를 근거해 확률적으로 결정됩니다.
   이처럼 다음 시점의 상태가 과거의 사건에 상관없이 현재 시점의 사건에 의해 결정되는 성질을 [무기억성(Memorylessness)](https://en.wikipedia.org/wiki/Memorylessness)이라고 합니다.

   <!-- 무작위 행보 시행의 성질 -->
   가령, 2차원 공간에서 원점$O$ $(0,0)$을 초기 시점($t=0$)의 상태로 정해 무작위 행보를 시행합니다.
   가능한 이동 방향을 나타내는 벡터들 $(0,+1)$, $(0,-1)$, $(+1,0)$, $(-1,0)$ 중에서 무작위로 하나를 골라 현재 시점 $t$의 상태(좌표)에 더합니다.
   각 벡터가 선택될 확률은 균등하므로 각각 25%입니다.
   따라서, 다음 시점 ($t+1$)의 좌표의 기댓값은 $(0,0)$으로 초기 상태의 좌표인 원점$O$와 동일합니다.
   이는 다음의 시점에서도 똑같이 적용되므로, 임의의 시점 t의 좌표의 기댓값은 초기 상태의 좌표임을 알 수 있습니다.

   하지만 좌표의 분산은 그렇지 않습니다.
   한번 이동할 때마다, (1/16, 1/16)씩 분산이 증가합니다.
   따라서, 임의의 시점 t의 좌표의 기댓값은 초기 상태인 (0,0)이지만, 점점 그 분산은 커지므로 실제로 좌표가 (0,0)에 있을 확률은 낮습니다.

   실제로, 무작위 행보 초기에는 좌표들이 원점 근처에 머물러 심지어는 원점으로 다시 돌아가기도 하나,
   행보가 어느정도 진행되면 원점에서부터 멀어져 원점으로 다시 돌아갈 확률이 매우 희박해집니다.

   ![무작위 행보의 예시](./resources/Random_Walk.png)
   *그림2. 무작위 행보의 예시*

   다른 관점에서 생각해보면, 좌표 공간에서 무작위 행보를 시행한다는 것은 그 좌표 공간을 탐색하는 것과 같습니다.
   우리가 일반적으로 생각하는 유클리디언 공간은 규칙적이고 쉽기 때문에 좌표 공간을 탐색한다는 것이 가치있다고 생각되지 않습니다.
   하지만, 네트워크 데이터의 자료구조인 그래프에서는 어떨까요?

## 3. Random Walks on Graphs

   <!-- 랜덤워크를 그래프에도 적용할 수 있음을 보인다. -->
   그래프도 무작위 행보를 시행할 수 있는 공간입니다.
   그래프 내 임의의 정점을 시작으로, 이웃하는 정점들 중 하나를 무작위로 골라 다음 행보로 결정하는 과정을 행보의 길이만큼 반복합니다.
   이렇게 얻어진 일련의 정점들이 그래프에서의 무작위 행보 시행 결과입니다.

   <!-- 그래프에서 랜덤워크 시행의 의미 -->
   앞서 이야기했듯이, 임의의 공간에서 무작위 행보를 시행한다는 것은 그 공간을 탐색한다는 것입니다.
   그래프에서 무작위 행보를 시행하면 그래프를 탐색할 수 있습니다.
   쉽고 규칙적인 유클리디언 공간과 달리, 그래프는 복잡하고 불규칙적이기 때문에 무작위 행보를 이용해 그래프의 탐색하는 것은 유의미한 과정입니다.

   그래프에서 무작위 행보를 시행하면 그래프의 구조정보를 담아낼 수 있습니다.
   구조 정보란 정점들 간 이웃 관계, [커뮤니티](https://en.wikipedia.org/wiki/Community_structure) 정보 등을 말합니다.
   가령, 그래프 내 존재하는 한 정점 A가 있습니다.
   정점 A를 시작으로 무작위 행보를 한 번 시행해 얻은 샘플에는 그래프에서 정점 A가 위치한 곳 주변의 구조 정보가 일부 들어있다고 생각할 수 있습니다.

   <!-- 랜덤워크를 충분히 시행하여 확률 과정의 기댓값을 구함. -->
   무작위 행보는 확률과정이기때문에 한 번의 시행으로는 구조 정보를 모두 담을 수 없을 것입니다.
   정점 A를 시작으로 무작위 행보를 여러번 시행해 충분한 숫자의 샘플들을 얻는다면, 큰 수의 법칙에 의해 정점 A 주변의 구조적인 정보를 근사해 낼 수 있습니다.
   무작위 행보 샘플들을 살펴보았을 때 유난히 자주 등장하는 정점B가 있다면, 정점B는 정점A가 속한 커뮤니티에서 중심적인 역할은 하는 정점일 것입니다.
   정점 A가 위치한 지역에서 중심적인 역할을 하는 정점B가 존재한다면, 앞서 얻은 무작위 행보 샘플들에서 정점B가 많이 등장할 것입니다.

   무작위 행보의 샘플들을 충분히 얻은 후, 각 샘플을 하나의 문장으로, 샘플을 구성하는 정점들을 단어로 간주하여 단어 임베딩을 적용해 정점의 임베딩을 얻습니다.
   이와 같은 네트워크 임베딩 방법은 Deepwalk에서 소개되었습니다.
   후속 연구들에도 큰 영향을 주었습니다.

## 4. Markov Chain

   그래프에서의 무작위 행보는 [마코프 연쇄](https://en.wikipedia.org/wiki/Markov_chain)와 매우 연관이 깊습니다.

   가령, 임의의 그래프 G로부터 얻은 임의의 정점 쌍 (v,u)가 있습니다.
   정점 v로부터 출발해 하나의 간선을 거쳐서, 즉 단 한번 이동했을 때 그 정점이 u일 확률을 계산합니다.
   별다른 제약 조건이 없다며면 그 확률을 1/(v와 이웃하는 정점 수)일 것입니다.
   이 확률을 가중치 m_vu라고 하겠습니다.
   그러면 v와 이웃하지 않는 정점들에 대해서는 그 가중치가 0이 되고, 이웃하는 정점들과의 가중치 총합은 1이 됩니다.
   이러한 방식으로 모든 정점 쌍에 대해서 가중치를 계산하면 |V|x|V| 가중치 행렬M을 얻을 수 있습니다.
   이 행렬은 정의에 따라 확률 행렬(Stochatic Matrix)의 조건을 만족하며, 마코프 연쇄에서 말하는 전이 행렬(Transition Matrix)로 사용될 수 있습니다.

   이 가중치 행렬M을 전이 행렬로 삼아 각 정점에 담긴 정보에 대해 마코프 연쇄를 시행할 수 있습니다.
   앞서 전이행렬을 잘 만들었다면, 마코프 연쇄 과정을 충분히 시행했을 때 각 정점들의 정보는 수렴한다는 것은 증명되어 있습니다.
   마치, 각 정점이 자신의 정보를 이웃하는 정점들에게 전파하고, 동시에 이웃하는 정점들로부터 정보를 전달받는 과정을 반복하는 것과 같습니다.
   그렇게 하다보면 각 정점이 정보들이 마코프 연쇄의 수렴 이론에 따라 어떤 평형 상태에 수렴하게 됩니다.
   <!-- 그 수렴 상태에서 정점 정보들의 분포가 그래프의 구조정보가 잘 반영된 상태라고 볼 수 있습니다. -->

   <!-- 초기 임베딩의 필요성 -->
   마코프 연쇄를 시행하기 위해서는 초기 상태가 필요한데, 그래프를 구성하는 정점들의 초기 임베딩으로 대체할 수 있습니다.
   정점의 임베딩을 구하려는데, 정점의 초기 임베딩이 필요하다는게 모순일 수 있으나, 초기 임베딩은 무엇이든 될 수 있습니다.
   정점이 담고 있는 각종 정보들(이미지, 텍스트 등)의 임베딩을 구해 활용 할 수도 있고, 각 정점들의 라벨들의 one-hot encoding을 활용 할 수도 있습니다.
   이러한 것들조차 없다면, 무작위로 초기화에서 활용해도 좋습니다.
   마코프 연쇄를 시행에 수렴 상태에 다다르면 무작위로 초기화한 정보라도 적절하게 나눠갖게 됩니다.

   이러한 관점에서 볼 때, 마코프 연쇄를 활용한 방법은 기존의 정점 임베딩을 더 최적화하는 방법이라고 생각할 수도 있겠습니다.

## 5. Optimizing the Nodes' Embeddings

   본 연구에서는 정점의 내적 정보와 관계 정보를 이용해 정점의 임베딩을 구하는 네트워크 임베딩 기법을 소개합니다.

   정점의 내적 정보란 정점에 내재된 고유한 정보로, 이웃하는 정점에 영향을 받지 않습니다.
   예를 들어, 어느 사회관계망의 '사용자1'은 A 대학에 재학중입니다.
   '사용자1'은 사회관계망을 구성하는 여러 정점들 중 하나이며, A 대학은 그 내적 정보입니다.
   '사용자1'은 같은 A 대학에 재학중인 다른 사용자들과 친구 관계를 많이 맺겠지만 B 대학에 다니는 사용자들과도 친구 관계를 맺을 수 있습니다.
   그렇다고 해서 '사용자1'의 재학중인 대학이 'A대학과 B대학 중간 즈음 어딘가'로 바뀌지 않습니다.

   관계 정보란 어떤 정점과 이웃하는 정점들 사이의 관계가 반영된 정보로 기존의 네트워크 임베딩 기법들이 중점적으로 다루던 것과 같습니다.
   어떤 정점이 이웃하는 정점들과 이루는 작은 규모의 지역적인 네트워크의 구조 정보를 뜻합니다.
   사전 연구들에서는 무작위 행보를 시행해 관계 정보를 임베딩했다면 본 연구에서는 마코프 연쇄를 시행합니다.
   각 정점들이 연결되어 있는 구조에 따라, 정보를 전달하고 또 동시에 전달받으면서 정보의 평형 상태를 찾아나갑니다.

   본 연구에서 제안하는 임의의 네트워크에서 정점의 정보는 자신의 내적 정보와 관계 정보의 합으로 정의합니다.

   $$ z_v = x_v + \gamma\sum_{u \in N(v)}z_u $$

   임의의 그래프 $G=(V,E)$가 주어졌을 때, 임의의 정점 $v \in V$에 대한 임베딩 $z_v \in R^d$는 $v$의 내적 정보 임베딩 $x_v \in R^d$와, $v$와 이웃하는 정점들 $N(v)$의 임베딩의 합을 더한 값으로 정의합니다.
### 5.1 Content- and Link-Aware Node Embeddings
   
   
   
### 5.2 Measuring Node Similarity

   
